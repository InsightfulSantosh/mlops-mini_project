name: CI Pipeline
on: push

jobs:
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # ğŸ› ï¸ Job 1: Setup Environment (Shared Dependency)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  setup-environment:
    runs-on: ubuntu-latest
    outputs:
      python-cache-key: ${{ steps.cache-pip.outputs.cache-key }}
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0  # Required for full DVC commit history

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Cache pip dependencies
        id: cache-pip
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install Dependencies
        run: |
          pip install -r requirements.txt
          pip install dvc[s3] dagshub mlflow

      - name: Configure DVC & MLflow
        env:
          DAGSHUB_USER: ${{ secrets.DAGSHUB_USER }}
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          # Configure DVC authentication for DagsHub
          dvc remote modify origin --local auth basic
          dvc remote modify origin --local user $DAGSHUB_USER
          dvc remote modify origin --local password $DAGSHUB_TOKEN

          # Configure S3 storage
          dvc remote add -d s3storage s3://your-data-bucket/dvc-store
          dvc remote modify s3storage endpointurl https://s3.ap-southeast-2.amazonaws.com
          dvc remote modify s3storage --local access_key_id $AWS_ACCESS_KEY_ID
          dvc remote modify s3storage --local secret_access_key $AWS_SECRET_ACCESS_KEY
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # ğŸ“¥ Job 2: Configure DVC & Pull Data
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  pull-dvc-data:
    runs-on: ubuntu-latest
    needs: setup-environment
    if: success()
    env:
      AWS_REGION: ${{ secrets.AWS_REGION }}  # Use GitHub Secrets for AWS region
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Restore Virtual Environment
        uses: actions/cache@v3
        with:
          path: venv
          key: ${{ needs.setup-environment.outputs.venv-cache-key }}

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Configure DVC S3 Remote
        run: |
          set -e
          source venv/bin/activate
          
          dvc remote default origin

      - name: Pull DVC Data
        run: |
          set -e
          source venv/bin/activate
          dvc pull -v

